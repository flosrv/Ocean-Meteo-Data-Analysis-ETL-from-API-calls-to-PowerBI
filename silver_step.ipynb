{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "from imports import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_user = \"flosrv\"\n",
    "password = \"Nesrine123\"\n",
    "host = \"localhost\"\n",
    "port = 3306\n",
    "database = \"Oceanography_data_analysis\"\n",
    "metadata = MetaData()\n",
    "# Connect to the database\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{mysql_user}:{password}@{host}/{database}\", isolation_level ='AUTOCOMMIT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour r√©cup√©rer les tables dont le nom commence par un pr√©fixe sp√©cifique\n",
    "def get_tables_starting_with(engine, prefix: str):\n",
    "    inspector = inspect(engine)\n",
    "    all_tables = inspector.get_table_names()\n",
    "    tables_with_prefix = [table for table in all_tables if table.startswith(prefix)]\n",
    "    return tables_with_prefix\n",
    "\n",
    "# Fonction pour r√©cup√©rer les donn√©es de chaque table (en ignorant l'absence de tables)\n",
    "def get_data_from_table(engine, table_name):\n",
    "    try:\n",
    "        query = f\"SELECT * FROM `{table_name}`\"  # Utilisation de backticks pour les noms de tables\n",
    "        df = pd.read_sql(query, engine)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur lors de la r√©cup√©ration des donn√©es pour la table {table_name}: {e}\")\n",
    "        return None  # Retourner None en cas d'erreur\n",
    "    \n",
    "def clean_dataframe(df):\n",
    "    for column in df.columns:\n",
    "        # Calculer le pourcentage de valeurs manquantes\n",
    "        missing_percentage = df[column].isnull().mean() * 100\n",
    "        \n",
    "        # Supprimer la colonne si elle est totalement nulle\n",
    "        if df[column].isnull().sum() == len(df[column]):\n",
    "            df = df.drop(columns=[column])\n",
    "            continue\n",
    "        \n",
    "        # Si plus de 50% des valeurs sont manquantes, on retire la colonne sauf si c'est num√©rique\n",
    "        if missing_percentage > 50:\n",
    "            if df[column].dtype not in ['float64', 'int64']:  # Ne pas supprimer les colonnes num√©riques\n",
    "                df = df.drop(columns=[column])\n",
    "        else:\n",
    "            # Si la colonne est num√©rique, on remplace les NaN par la m√©diane\n",
    "            if df[column].dtype in ['float64', 'int64']:  # v√©rifier si c'est une colonne num√©rique\n",
    "                median_value = df[column].median()\n",
    "                df[column].fillna(median_value, inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les Donn√©es des Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Nombre total de stations au d√©but : 41\n",
      "üìù Stations initiales :\n",
      "  - Station ID: 41008\n",
      "  - Station ID: 41044\n",
      "  - Station ID: 41049\n",
      "  - Station ID: 42001\n",
      "  - Station ID: 42002\n",
      "  - Station ID: 42012\n",
      "  - Station ID: 42036\n",
      "  - Station ID: 42056\n",
      "  - Station ID: 42058\n",
      "  - Station ID: 44007\n",
      "  - Station ID: 44020\n",
      "  - Station ID: 44025\n",
      "  - Station ID: 44027\n",
      "  - Station ID: 44065\n",
      "  - Station ID: 46001\n",
      "  - Station ID: 46006\n",
      "  - Station ID: 46014\n",
      "  - Station ID: 46022\n",
      "  - Station ID: 46025\n",
      "  - Station ID: 46027\n",
      "  - Station ID: 46029\n",
      "  - Station ID: 46053\n",
      "  - Station ID: 46069\n",
      "  - Station ID: 46071\n",
      "  - Station ID: 46072\n",
      "  - Station ID: 46078\n",
      "  - Station ID: 46084\n",
      "  - Station ID: 46086\n",
      "  - Station ID: 46087\n",
      "  - Station ID: 46088\n",
      "  - Station ID: 51000\n",
      "  - Station ID: 51001\n",
      "  - Station ID: 51002\n",
      "  - Station ID: burl1\n",
      "  - Station ID: ffia2\n",
      "  - Station ID: lonf1\n",
      "  - Station ID: mdrm1\n",
      "  - Station ID: mrka2\n",
      "  - Station ID: pota2\n",
      "  - Station ID: sanf1\n",
      "  - Station ID: sbio1\n"
     ]
    }
   ],
   "source": [
    "# Charger les donn√©es\n",
    "# Dictionnaire pour stocker les donn√©es tri√©es par Station ID\n",
    "buoy_datas = {}\n",
    "\n",
    "# R√©cup√©rer les tables commen√ßant par 'br_'\n",
    "bronze_tables = get_tables_starting_with(engine, prefix='br_')\n",
    "\n",
    "# Parcourir les tables et les organiser par Station ID et type (marine ou meteo)\n",
    "for table in bronze_tables:\n",
    "    parts = table.split('_')\n",
    "    if len(parts) < 4:\n",
    "        continue  # Format inattendu\n",
    "\n",
    "    station_id = str(parts[1])  # Convertir en string pour √©viter KeyError\n",
    "    label = parts[2].lower()  # \"marine\" ou \"meteo\"\n",
    "\n",
    "    df = get_data_from_table(engine, table)\n",
    "\n",
    "    if station_id not in buoy_datas:\n",
    "        buoy_datas[station_id] = {\"Marine Dataframe\": None, \"Meteo Dataframe\": None}  \n",
    "\n",
    "    if label == \"marine\":\n",
    "        buoy_datas[station_id][\"Marine Dataframe\"] = df\n",
    "    elif label == \"meteo\":\n",
    "        buoy_datas[station_id][\"Meteo Dataframe\"] = df  \n",
    "\n",
    "# V√©rification\n",
    "print(f\"üìä Nombre total de stations au d√©but : {len(buoy_datas)}\")\n",
    "print(\"üìù Stations initiales :\")\n",
    "for station_id in buoy_datas.keys():\n",
    "    print(f\"  - Station ID: {station_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting Missing Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Traitement de la station ID : 41008\n",
      "‚úÖ Marine Dataframe: 7188 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 41044\n",
      "‚úÖ Marine Dataframe: 7157 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 41049\n",
      "‚úÖ Marine Dataframe: 7161 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 42001\n",
      "‚úÖ Marine Dataframe: 3727 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 42002\n",
      "‚úÖ Marine Dataframe: 3884 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 42012\n",
      "‚úÖ Marine Dataframe: 7142 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 42036\n",
      "‚úÖ Marine Dataframe: 7127 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 42056\n",
      "‚úÖ Marine Dataframe: 7166 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 42058\n",
      "‚úÖ Marine Dataframe: 7144 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 44007\n",
      "‚úÖ Marine Dataframe: 7167 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 44020\n",
      "‚úÖ Marine Dataframe: 7164 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 44025\n",
      "‚úÖ Marine Dataframe: 7183 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 44027\n",
      "‚úÖ Marine Dataframe: 7164 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 44065\n",
      "‚úÖ Marine Dataframe: 7152 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46001\n",
      "‚úÖ Marine Dataframe: 7160 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46006\n",
      "‚úÖ Marine Dataframe: 7162 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46014\n",
      "‚úÖ Marine Dataframe: 7204 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46022\n",
      "‚úÖ Marine Dataframe: 7221 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46025\n",
      "‚úÖ Marine Dataframe: 7199 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46027\n",
      "‚úÖ Marine Dataframe: 7197 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46029\n",
      "‚úÖ Marine Dataframe: 7199 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46053\n",
      "‚úÖ Marine Dataframe: 7205 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46069\n",
      "‚úÖ Marine Dataframe: 7181 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46071\n",
      "‚úÖ Marine Dataframe: 7169 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46072\n",
      "‚úÖ Marine Dataframe: 7168 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46078\n",
      "‚úÖ Marine Dataframe: 7160 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46084\n",
      "‚úÖ Marine Dataframe: 7162 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46086\n",
      "‚úÖ Marine Dataframe: 7198 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46087\n",
      "‚úÖ Marine Dataframe: 7208 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 46088\n",
      "‚úÖ Marine Dataframe: 7198 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 51000\n",
      "‚úÖ Marine Dataframe: 7166 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 51001\n",
      "‚úÖ Marine Dataframe: 7160 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : 51002\n",
      "‚úÖ Marine Dataframe: 7157 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : burl1\n",
      "‚úÖ Marine Dataframe: 1205 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : ffia2\n",
      "‚úÖ Marine Dataframe: 1206 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : lonf1\n",
      "‚úÖ Marine Dataframe: 7094 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : mdrm1\n",
      "‚úÖ Marine Dataframe: 1205 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : mrka2\n",
      "‚úÖ Marine Dataframe: 2409 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : pota2\n",
      "‚úÖ Marine Dataframe: 2406 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : sanf1\n",
      "‚úÖ Marine Dataframe: 7126 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la station ID : sbio1\n",
      "‚úÖ Marine Dataframe: 1205 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üìä Nombre de stations restantes : 41\n",
      "üóëÔ∏è Nombre de stations supprim√©es : 0\n"
     ]
    }
   ],
   "source": [
    "# Virer les df manquantes\n",
    "stations_removed = 0\n",
    "stations_to_remove = []\n",
    "\n",
    "for station_id, data in buoy_datas.items():\n",
    "    try:\n",
    "        print(f\"\\nüîç Traitement de la station ID : {station_id}\")\n",
    "\n",
    "        marine_data = data.get(\"Marine Dataframe\")\n",
    "        meteo_data = data.get(\"Meteo Dataframe\")\n",
    "\n",
    "        if marine_data is None or meteo_data is None:\n",
    "            print(f\"‚ö†Ô∏è Dataframe manquante pour la station {station_id}. Suppression.\")\n",
    "            stations_to_remove.append(station_id)\n",
    "            stations_removed += 1\n",
    "            continue \n",
    "\n",
    "        print(f\"‚úÖ Marine Dataframe: {marine_data.shape[0]} lignes\")\n",
    "        print(f\"‚úÖ Meteo Dataframe: {meteo_data.shape[0]} lignes\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur sur la station {station_id}: {str(e)}\")\n",
    "\n",
    "# Supprimer les stations sans donn√©es\n",
    "for station_id in stations_to_remove:\n",
    "    del buoy_datas[station_id]\n",
    "\n",
    "print(f\"\\nüìä Nombre de stations restantes : {len(buoy_datas)}\")\n",
    "print(f\"üóëÔ∏è Nombre de stations supprim√©es : {stations_removed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Enrichment with MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Traitement de la Station ID: 41008\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : grays reef\n",
      "üÜî Station ID : 41008\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 31.40N, Longitude = 80.87W\n",
      "üåä Water Depth : 16 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=41008\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7188 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 41044\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : ne st martin\n",
      "üÜî Station ID : 41044\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 21.58N, Longitude = 58.63W\n",
      "üåä Water Depth : 5419 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=41044\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7157 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 41049\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : south bermuda\n",
      "üÜî Station ID : 41049\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 27.50N, Longitude = 62.27W\n",
      "üåä Water Depth : 5480 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=41049\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7161 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 42001\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : mid gulf\n",
      "üÜî Station ID : 42001\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 25.93N, Longitude = 89.66W\n",
      "üåä Water Depth : 3200 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=42001\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 3727 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 42002\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : west gulf\n",
      "üÜî Station ID : 42002\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 25.95N, Longitude = 93.78W\n",
      "üåä Water Depth : 3208 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=42002\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 3884 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 42012\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : orange beach\n",
      "üÜî Station ID : 42012\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 30.06N, Longitude = 87.55W\n",
      "üåä Water Depth : 23.5 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=42012\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7142 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 42036\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : west tampa\n",
      "üÜî Station ID : 42036\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 28.50N, Longitude = 84.50W\n",
      "üåä Water Depth : 53.3 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=42036\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7127 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 42056\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : yucatan basin\n",
      "üÜî Station ID : 42056\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 19.82N, Longitude = 84.98W\n",
      "üåä Water Depth : 4578 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=42056\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7166 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 42058\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : central caribbean\n",
      "üÜî Station ID : 42058\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 14.51N, Longitude = 75.15W\n",
      "üåä Water Depth : 4136 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=42058\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7144 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 44007\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : portland\n",
      "üÜî Station ID : 44007\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 43.52N, Longitude = 70.14W\n",
      "üåä Water Depth : 49 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=44007\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7167 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 44020\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : nantucket sound\n",
      "üÜî Station ID : 44020\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 41.50N, Longitude = 70.28W\n",
      "üåä Water Depth : 16.5 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=44020\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7164 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 44025\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : long island\n",
      "üÜî Station ID : 44025\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 40.26N, Longitude = 73.17W\n",
      "üåä Water Depth : 40.2 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=44025\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7183 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 44027\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : jonesport, me\n",
      "üÜî Station ID : 44027\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 44.28N, Longitude = 67.30W\n",
      "üåä Water Depth : 188 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=44027\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7164 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 44065\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : new york harbor entrance\n",
      "üÜî Station ID : 44065\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 40.37N, Longitude = 73.70W\n",
      "üåä Water Depth : 26 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=44065\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7152 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46001\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : western gulf of alaska\n",
      "üÜî Station ID : 46001\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 56.30N, Longitude = 148.03W\n",
      "üåä Water Depth : 4123 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46001\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7160 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46006\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : southeast papa\n",
      "üÜî Station ID : 46006\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 40.76N, Longitude = 137.38W\n",
      "üåä Water Depth : 4347 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46006\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7162 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46014\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : pt arena\n",
      "üÜî Station ID : 46014\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 39.23N, Longitude = 123.98W\n",
      "üåä Water Depth : 335 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46014\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7204 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46022\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : eel river\n",
      "üÜî Station ID : 46022\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 40.72N, Longitude = 124.54W\n",
      "üåä Water Depth : 456 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 3.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46022\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7221 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46025\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : santa monica basin\n",
      "üÜî Station ID : 46025\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 33.76N, Longitude = 119.05W\n",
      "üåä Water Depth : 890 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46025\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7199 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46027\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : st georges\n",
      "üÜî Station ID : 46027\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 41.84N, Longitude = 124.38W\n",
      "üåä Water Depth : 60 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46027\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7197 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46029\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : columbia river bar\n",
      "üÜî Station ID : 46029\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 46.16N, Longitude = 124.49W\n",
      "üåä Water Depth : 131 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46029\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7199 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46053\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : east santa barbara\n",
      "üÜî Station ID : 46053\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 34.24N, Longitude = 119.84W\n",
      "üåä Water Depth : 405 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.1\n",
      "üå¨Ô∏è Barometer Elevation : 1.8\n",
      "üí® Anemometer Height : 3.2\n",
      "üå§Ô∏è Air Temp Height : 2.8\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46053\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7205 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46069\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : south santa rosa\n",
      "üÜî Station ID : 46069\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 33.68N, Longitude = 120.21W\n",
      "üåä Water Depth : 977.8 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46069\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7181 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46071\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : western aleutians\n",
      "üÜî Station ID : 46071\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 51.04N, Longitude = 179.76E\n",
      "üåä Water Depth : 3967 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46071\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7169 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46072\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : central aleutians 230 nm sw dutch harbor\n",
      "üÜî Station ID : 46072\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 51.65N, Longitude = 172.15W\n",
      "üåä Water Depth : 3589 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46072\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7168 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46078\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : albatross bank\n",
      "üÜî Station ID : 46078\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 55.56N, Longitude = 152.60W\n",
      "üåä Water Depth : 5361 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46078\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7160 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46084\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : cape edgecumbe\n",
      "üÜî Station ID : 46084\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 56.61N, Longitude = 136.04W\n",
      "üåä Water Depth : 1149 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46084\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7162 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46086\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : san clemente basin\n",
      "üÜî Station ID : 46086\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 32.50N, Longitude = 118.05W\n",
      "üåä Water Depth : 1844.7 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46086\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7198 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46087\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : neah bay\n",
      "üÜî Station ID : 46087\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 48.49N, Longitude = 124.73W\n",
      "üåä Water Depth : 262.4 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46087\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7208 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 46088\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : new dungeness\n",
      "üÜî Station ID : 46088\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 48.33N, Longitude = 123.18W\n",
      "üåä Water Depth : 115.5 m\n",
      "üå°Ô∏è Sea Temp Depth : 2\n",
      "üå¨Ô∏è Barometer Elevation : 2.4\n",
      "üí® Anemometer Height : 3.8\n",
      "üå§Ô∏è Air Temp Height : 3.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=46088\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7198 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 51000\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : northern hawaii one\n",
      "üÜî Station ID : 51000\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 23.53N, Longitude = 153.79W\n",
      "üåä Water Depth : 4762 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=51000\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7166 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 51001\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : northwestern hawaii one\n",
      "üÜî Station ID : 51001\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 24.48N, Longitude = 162.03W\n",
      "üåä Water Depth : 4895 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.1\n",
      "üå¨Ô∏è Barometer Elevation : 1.8\n",
      "üí® Anemometer Height : 3.2\n",
      "üå§Ô∏è Air Temp Height : 2.8\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=51001\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7160 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: 51002\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : southwest hawaii\n",
      "üÜî Station ID : 51002\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 17.07N, Longitude = 157.75W\n",
      "üåä Water Depth : 4979 m\n",
      "üå°Ô∏è Sea Temp Depth : 1.5\n",
      "üå¨Ô∏è Barometer Elevation : 2.7\n",
      "üí® Anemometer Height : 4.1\n",
      "üå§Ô∏è Air Temp Height : 3.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=51002\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7157 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: burl1\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : southwest pass, la\n",
      "üÜî Station ID : BURL1\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 28.91N, Longitude = 89.43W\n",
      "üåä Water Depth : N/A\n",
      "üå°Ô∏è Sea Temp Depth : None\n",
      "üå¨Ô∏è Barometer Elevation : 13.4\n",
      "üí® Anemometer Height : 38\n",
      "üå§Ô∏è Air Temp Height : 13.7\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=BURL1\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 1205 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: ffia2\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : five fingers, ak\n",
      "üÜî Station ID : FFIA2\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 57.27N, Longitude = 133.63W\n",
      "üåä Water Depth : N/A\n",
      "üå°Ô∏è Sea Temp Depth : None\n",
      "üå¨Ô∏è Barometer Elevation : 21.3\n",
      "üí® Anemometer Height : 22\n",
      "üå§Ô∏è Air Temp Height : 4.3\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=FFIA2\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 1206 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: lonf1\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : long key, fl\n",
      "üÜî Station ID : LONF1\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 24.84N, Longitude = 80.86W\n",
      "üåä Water Depth : N/A\n",
      "üå°Ô∏è Sea Temp Depth : None\n",
      "üå¨Ô∏è Barometer Elevation : 5.03\n",
      "üí® Anemometer Height : 6.34\n",
      "üå§Ô∏è Air Temp Height : 6.1\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=LONF1\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7094 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: mdrm1\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : mt. desert rock, me\n",
      "üÜî Station ID : MDRM1\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 43.97N, Longitude = 68.13W\n",
      "üåä Water Depth : N/A\n",
      "üå°Ô∏è Sea Temp Depth : None\n",
      "üå¨Ô∏è Barometer Elevation : 16.5\n",
      "üí® Anemometer Height : 22.6\n",
      "üå§Ô∏è Air Temp Height : 15.2\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=MDRM1\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 1205 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: mrka2\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : middle rock light, ak\n",
      "üÜî Station ID : MRKA2\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 61.08N, Longitude = 146.66W\n",
      "üåä Water Depth : N/A\n",
      "üå°Ô∏è Sea Temp Depth : None\n",
      "üå¨Ô∏è Barometer Elevation : 10.9\n",
      "üí® Anemometer Height : 15.9\n",
      "üå§Ô∏è Air Temp Height : 15.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=MRKA2\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 2409 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: pota2\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : potato point, ak\n",
      "üÜî Station ID : POTA2\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 61.06N, Longitude = 146.70W\n",
      "üåä Water Depth : N/A\n",
      "üå°Ô∏è Sea Temp Depth : None\n",
      "üå¨Ô∏è Barometer Elevation : 8.5\n",
      "üí® Anemometer Height : 10\n",
      "üå§Ô∏è Air Temp Height : 9.1\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=POTA2\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 2406 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: sanf1\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : sand key, fl\n",
      "üÜî Station ID : SANF1\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 24.46N, Longitude = 81.88W\n",
      "üåä Water Depth : N/A\n",
      "üå°Ô∏è Sea Temp Depth : None\n",
      "üå¨Ô∏è Barometer Elevation : 13.6\n",
      "üí® Anemometer Height : 14.8\n",
      "üå§Ô∏è Air Temp Height : 14.6\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=SANF1\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 7126 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n",
      "\n",
      "üîç Traitement de la Station ID: sbio1\n",
      "\n",
      "üîç D√©but du parsing de la bou√©e...\n",
      "üåç Zone de la station : south bass island, oh\n",
      "üÜî Station ID : SBIO1\n",
      "‚úÖ Coordonn√©es extraites : Latitude = 41.63N, Longitude = 82.84W\n",
      "üåä Water Depth : N/A\n",
      "üå°Ô∏è Sea Temp Depth : None\n",
      "üå¨Ô∏è Barometer Elevation : 178.4\n",
      "üí® Anemometer Height : 24.3\n",
      "üå§Ô∏è Air Temp Height : 23.4\n",
      "üîó URL de la bou√©e : https://www.ndbc.noaa.gov/station_page.php?station=SBIO1\n",
      "‚úÖ Parsing termin√© !\n",
      "\n",
      "‚úÖ Marine Dataframe: 1205 lignes\n",
      "‚úÖ Meteo Dataframe: 2496 lignes\n"
     ]
    }
   ],
   "source": [
    "total_merged_rows = 0  # Variable pour compter le nombre total de lignes fusionn√©es\n",
    "\n",
    "################## Data enrichment ##########################################\n",
    "\n",
    "for station_id, data in buoy_datas.items():\n",
    "    print(f\"\\nüîç Traitement de la Station ID: {station_id}\")\n",
    "\n",
    "    marine_df = data[\"Marine Dataframe\"]\n",
    "    meteo_df = data[\"Meteo Dataframe\"]\n",
    "\n",
    "    try:\n",
    "        buoy_metadata = get_station_metadata(station_id)\n",
    "        parsed_data = parse_buoy_json(buoy_metadata)\n",
    "\n",
    "        # Ajouter les m√©tadonn√©es dans la DataFrame Marine\n",
    "        if marine_df is not None:\n",
    "            for key, value in parsed_data.items():\n",
    "                marine_df[key] = value \n",
    "\n",
    "        # Mise √† jour du dictionnaire avec les m√©tadonn√©es\n",
    "        data.update(parsed_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur de r√©cup√©ration des m√©tadonn√©es pour {station_id}: {e}\")\n",
    "\n",
    "    print(f\"‚úÖ Marine Dataframe: {marine_df.shape[0]} lignes\" if marine_df is not None else \"‚ö†Ô∏è Marine Dataframe: Aucune donn√©e\")\n",
    "    print(f\"‚úÖ Meteo Dataframe: {meteo_df.shape[0]} lignes\" if meteo_df is not None else \"‚ö†Ô∏è Meteo Dataframe: Aucune donn√©e\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1205 entries, 0 to 1204\n",
      "Data columns (total 26 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   wind_direction           1202 non-null   float64       \n",
      " 1   wind_speed               1205 non-null   float64       \n",
      " 2   wind_gust                1205 non-null   float64       \n",
      " 3   wave_height              0 non-null      object        \n",
      " 4   dominant_wave_period     0 non-null      object        \n",
      " 5   average_wave_period      0 non-null      object        \n",
      " 6   dominant_wave_direction  0 non-null      object        \n",
      " 7   pressure                 1205 non-null   float64       \n",
      " 8   air_temperature          1198 non-null   float64       \n",
      " 9   water_temperature        0 non-null      object        \n",
      " 10  dewpoint                 0 non-null      object        \n",
      " 11  visibility               0 non-null      object        \n",
      " 12  3hr_pressure_tendency    1202 non-null   float64       \n",
      " 13  water_level_above_mean   0 non-null      object        \n",
      " 14  Datetime                 1205 non-null   datetime64[ns]\n",
      " 15  Lat                      1205 non-null   object        \n",
      " 16  Lon                      1205 non-null   object        \n",
      " 17  Water_depth              1205 non-null   object        \n",
      " 18  station_zone             1205 non-null   object        \n",
      " 19  lat_buoy                 1205 non-null   object        \n",
      " 20  lon_buoy                 1205 non-null   object        \n",
      " 21  sea_temp_depth           0 non-null      object        \n",
      " 22  Barometer_elevation      1205 non-null   object        \n",
      " 23  Anemometer_height        1205 non-null   object        \n",
      " 24  Air_temp_height          1205 non-null   object        \n",
      " 25  url                      1205 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(6), object(19)\n",
      "memory usage: 244.9+ KB\n"
     ]
    }
   ],
   "source": [
    "marine_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des DataFrames fusionn√©s\n",
    "for station_id, data in buoy_datas.items():\n",
    "    try:\n",
    "        print(f\"\\nüîÑ Nettoyage des donn√©es pour la station {station_id}\")\n",
    "\n",
    "        marine_df = data[\"Marine Dataframe\"]\n",
    "        meteo_df = data[\"Meteo Dataframe\"]\n",
    "\n",
    "        if marine_df is None:\n",
    "            print(f\"‚ö†Ô∏è Station {station_id} ignor√©e: Marine DataFrame manquant)\")\n",
    "            continue\n",
    "        if meteo_df is None:\n",
    "            print(f\"‚ö†Ô∏è Station {station_id} ignor√©e: Meteo DataFrame manquant)\")\n",
    "            continue\n",
    "        \n",
    "\n",
    "        try:\n",
    "            cleaned_marine_df = clean_dataframe(marine_df)\n",
    "\n",
    "            # Ajouter le DataFrame nettoy√© au dictionnaire des r√©sultats\n",
    "            buoy_datas[station_id] = {'Cleaned Marine Dataframe': cleaned_marine_df}\n",
    "            print(f\"‚úÖ Nettoyage r√©ussi pour la station {station_id} ({cleaned_marine_df.shape[0]} lignes)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du nettoyage pour {station_id}: {e}\")\n",
    "\n",
    "# R√©sum√© final du nettoyage\n",
    "print(\"\\nüìä R√âSUM√â DU NETTOYAGE:\")\n",
    "print(f\"üìå Stations au d√©part : {len(buoy_datas)}\")\n",
    "print(f\"‚úÖ Stations nettoy√©es : {len([data for data in buoy_datas.values() if 'Cleaned Dataframe' in data])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Try to Merge ################################################################################\n",
    "list_ID =[]\n",
    "list_merged_df =[]\n",
    "\n",
    "for station_id, data in buoy_datas.items():\n",
    "    list_ID.append(station_id)\n",
    "    try:\n",
    "        print(f\"\\nüîÑ Fusion des DataFrames pour la station {station_id}\")\n",
    "\n",
    "        # V√©rifier si les deux DataFrames existent\n",
    "        if marine_df is None or meteo_df is None:\n",
    "            print(f\"‚ö†Ô∏è Station {station_id} ignor√©e (donn√©es manquantes)\")\n",
    "            continue\n",
    "\n",
    "        # Assurez-vous que la colonne 'Datetime' existe dans les deux DataFrames\n",
    "        if 'Datetime' not in marine_df.columns or 'Datetime' not in meteo_df.columns:\n",
    "            print(f\"‚ö†Ô∏è Station {station_id} ignor√©e (colonne 'Datetime' manquante)\")\n",
    "            continue\n",
    "\n",
    "        # Assurez-vous que la colonne 'Datetime' est dans le bon format datetime\n",
    "        marine_df['Datetime'] = pd.to_datetime(marine_df['Datetime'], errors='coerce')\n",
    "        meteo_df['Datetime'] = pd.to_datetime(meteo_df['Datetime'], errors='coerce')\n",
    "\n",
    "        # Ajouter le DataFrame fusionn√© au dictionnaire des r√©sultats\n",
    "        try:\n",
    "            # Tenter un merge inner sur la colonne temporelle 'Datetime'\n",
    "            merged_df = marine_df.merge(meteo_df, how=\"inner\", on=\"Datetime\")  # Ajuste 'timestamp' si n√©cessaire\n",
    "            buoy_datas[station_id]['Merged Dataframe'] = merged_df\n",
    "            list_merged_df.append(merged_df)\n",
    "        except Exception as e:\n",
    "            print(f'Error loading Merged Dataframe for Buoy{station_id}')\n",
    "        print(f\"‚úÖ Fusion r√©ussie pour la station {station_id} ({merged_df.shape[0]} lignes)\")\n",
    "\n",
    "        # Ajouter le nombre de lignes de ce DataFrame fusionn√© au total\n",
    "        total_merged_rows += merged_df.shape[0]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de la fusion pour {station_id}: {e}\")\n",
    "\n",
    "# R√©sum√© final de la fusion\n",
    "print(\"\\nüìä R√âSUM√â DE LA FUSION:\")\n",
    "print(f\"üìå Stations au d√©part : {len(buoy_datas)}\")\n",
    "print(f\"üìä Total de lignes fusionn√©es : {total_merged_rows}\")\n",
    "\n",
    "print(f'\\ntest Df:\\n{buoy_datas[\"42058\"]['Merged Dataframe']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{buoy_datas[\"42058\"]['Merged Dataframe'].shape}')\n",
    "print(f'\\n{buoy_datas[\"42058\"]['Merged Dataframe'].isnull().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{buoy_datas[\"42058\"]['Cleaned Dataframe'].shape}')\n",
    "print(f'\\n{buoy_datas[\"42058\"]['Cleaned Dataframe'].isnull().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_cols = [\n",
    "    \"wind_direction\", \"wind_speed\", \"wind_gust\", \"wave_height\",\n",
    "    \"dominant_wave_period\", \"average_wave_period\", \"dominant_wave_direction\",\n",
    "    \"pressure\", \"air_temperature\", \"water_temperature\", \"dewpoint\",\n",
    "    \"visibility\", \"3hr_pressure_tendency\", \"water_level_above_mean\"\n",
    "]\n",
    "\n",
    "meteo_cols = [\n",
    "    \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"precipitation\", \"rain\",\n",
    "    \"showers\", \"pressure_msl\", \"surface_pressure\", \"cloud_cover\", \"cloud_cover_low\",\n",
    "    \"cloud_cover_mid\", \"cloud_cover_high\", \"visibility\", \"wind_speed_10m\",\n",
    "    \"soil_temperature_0cm\", \"soil_moisture_0_to_1cm\"\n",
    "]\n",
    "\n",
    "col_to_rename={'temperature_2m': 'T¬∞(C¬∞)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (¬∞C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (km)',  'wind_direction': 'Wind Direction (¬∞)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (¬∞)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air T¬∞','water_temperature': 'Water T¬∞'}\n",
    "\n",
    "meteo_cols_to_delete = ['soil_temperature_0cm','rain', 'showers', 'is_day',\n",
    "                  'soil_moisture_0_to_1cm']\n",
    "\n",
    "for station_id, tables in buoy_datas.items():\n",
    "    marine_df = tables[\"Marine DataFrame\"]\n",
    "    marine_df = rename_columns(marine_df, col_to_rename)\n",
    "\n",
    "    marine_df = drop_columns_if_exist\n",
    "\n",
    "    meteo_df = tables[\"Meteo DataFrame\"]\n",
    "    meteo_df = rename_columns(meteo_df,col_to_rename)\n",
    "    meteo_df = drop_columns_if_exist(meteo_df, meteo_cols_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOUR RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling des donn√©es et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"üîÅ Processing and resampling marine data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Marine DataFrame\"] = process_datetime_column(tables[\"Marine DataFrame\"], column='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Marine Data for {station_id}: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"üîÅ Processing and resampling weather data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Meteo DataFrame\"] = process_datetime_column(tables[\"Meteo DataFrame\"], column='date')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Meteo Data for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Adding MetaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        df_merged = tables[\"Merged DataFrame\"]\n",
    "        print(f\"üîó Changing Data Types  for station {station_id}...\")\n",
    "        df_converted = convert_df_columns(df_merged)\n",
    "        tables[\"Converted DataFrame\"] = df_converted\n",
    "        \n",
    "        print(f\"Successfully Changed Data Types for Station {station_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error changing data types for station {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "\n",
    "        print(f\"üîó Cleaning DataFrame for station {station_id}...\")\n",
    "        df_converted = tables[\"Converted DataFrame\"]\n",
    "        \n",
    "        df_cleaned = clean_dataframe(df_converted)\n",
    "\n",
    "        tables[\"Cleaned DataFrame\"] = df_cleaned\n",
    "\n",
    "        print(f\"Successfully Cleaned DataFrame for Station {station_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error Cleaning DataFrame for station {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating All in One Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion finale de tous les DataFrames\n",
    "try:\n",
    "    print(\"üîÄ Merging all DataFrames into a final DataFrame...\")\n",
    "    dataframes_to_concat = [tables[\"Cleaned DataFrame\"] for tables in buoys_datas.values()]\n",
    "\n",
    "    df_final = pd.concat(dataframes_to_concat, ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during final merge: {e}\")\n",
    "    df_final = None\n",
    "\n",
    "# R√©sum√© final\n",
    "print(\"\\n‚≠êüèÜ Processing complete!\")\n",
    "print(f\"üî¢ Total stations processed: {len(buoys_datas)}\")\n",
    "\n",
    "if df_final is not None and not df_final.empty:\n",
    "    print(f\"üìù Final merged DataFrame size: {df_final.shape}\")\n",
    "else:\n",
    "    print(\"The DataFrame is either None or empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcourir toutes les colonnes contenant \"Station ID\" dans leur nom\n",
    "for column in df_final.columns:\n",
    "    if \"Station ID\" in column:\n",
    "        try:\n",
    "            # Tenter de convertir la colonne en num√©rique (en utilisant pd.to_numeric avec errors='coerce')\n",
    "            df_final[column] = pd.to_numeric(df_final[column], errors='raise')\n",
    "             # Si la conversion est r√©ussie, convertir en int\n",
    "            df_final[column] = df_final[column].astype(int) \n",
    "\n",
    "        except Exception as e:\n",
    "                print(f\"Error in Conversion Step 1 for column: {column}:\\n{e}\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            df_final[column] = df_final[column].astype(str)\n",
    "\n",
    "        except Exception as e:\n",
    "                print(f\"Error in Conversion Step 2 for column: {column}:\\n{e}\")\n",
    "            \n",
    "\n",
    "show_first_row(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = clean_dataframe(df_final)\n",
    "df_final.isnull().sum()\n",
    "df_final2 = df_final.dropna()\n",
    "print(f'{df_final2.shape}\\n\\n{df_final2.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2 = df_final2.round(2)\n",
    "show_first_row(df_final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2[['Daytime', 'Month']] = df_final2['Datetime'].apply(lambda x: get_day_time(x)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2=df_final2.round(2)\n",
    "show_first_row(df_final2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming, Dropping Useless Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(df_final2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Envoi Vers PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_in_table(engine=engine, schema = schema_silver, table_name='Silver_Table', df=df_final2, key_column='Datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer le dataframe pour la Station ID 42058\n",
    "df_42058 = df_final2[df_final2[\"Station ID\"] == 42058]\n",
    "df_42058.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming the df_cleaned DataFrame already exists and contains the required data\n",
    "\n",
    "# # First, load your Visual Crossing Weather Data (example, you may already have it)\n",
    "# # Assuming vc_meteo_data is the JSON response from Visual Crossing\n",
    "# # Example of flattening the JSON\n",
    "# df_vc_meteo = pd.json_normalize(vc_meteo_data, record_path=[\"days\", \"hours\"], meta=[\"days\"])\n",
    "\n",
    "# # Convert the datetimeEpoch from Visual Crossing Weather data into Date and Hour columns\n",
    "# df_vc_meteo[\"Date\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%Y-%m-%d\")\n",
    "# df_vc_meteo[\"Hour\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%H\")\n",
    "\n",
    "# # Filter data from df_vc_meteo for the last 30 days\n",
    "# today = datetime.now()\n",
    "# thirty_days_ago = today - timedelta(days=30)\n",
    "\n",
    "# today_str = today.strftime(\"%Y-%m-%d\")\n",
    "# thirty_days_ago_str = thirty_days_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# # Filter df_vc_meteo for the last 30 days\n",
    "# df_test_last_month = df_vc_meteo[['Date', 'Hour', 'windspeed']]\n",
    "# df_test_last_month = df_test_last_month[(df_test_last_month['Date'] >= thirty_days_ago_str) & \n",
    "#                                         (df_test_last_month['Date'] <= today_str)]\n",
    "\n",
    "# # Prepare df_cleaned for merging (add Date and Hour columns)\n",
    "# df_cleaned['Date'] = df_cleaned['Datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "# df_cleaned['Hour'] = df_cleaned['Datetime'].dt.strftime(\"%H\")\n",
    "\n",
    "# # Filter df_cleaned for the last 30 days\n",
    "# df_cleaned_last_month = df_cleaned[(df_cleaned['Date'] >= thirty_days_ago_str) & \n",
    "#                                    (df_cleaned['Date'] <= today_str)]\n",
    "\n",
    "# # Merge df_vc_meteo and df_cleaned based on Date and Hour\n",
    "# df_merged = df_test_last_month.merge(df_cleaned_last_month[['Date', 'Hour', 'Wind Speed (km/h)', 'wind_speed_10m']], \n",
    "#                                     on=['Date', 'Hour'], \n",
    "#                                     how='inner')\n",
    "\n",
    "# # Display the merged dataframe\n",
    "# print(df_merged.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_rename={'temperature_2m': 'T¬∞(C¬∞)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (¬∞C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (%)',  'wind_direction': 'Wind Direction (¬∞)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (¬∞)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air T¬∞','water_temperature': 'Water T¬∞'}\n",
    "\n",
    "df_cleaned = rename_columns(df_cleaned, col_to_rename)\n",
    "df_cleaned = drop_columns_if_exist(df_cleaned,['soil_temperature_0cm','rain', 'showers', 'is_day', 'id_x', 'id_y','soil_moisture_0_to_1cm'])\n",
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  R√©cup√©rer les donn√©es de l'API\n",
    "# vc_meteo_data = response.json()\n",
    "# print(vc_meteo_data)  # V√©rifiez les donn√©es r√©cup√©r√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normaliser les donn√©es JSON en DataFrame\n",
    "# df_vc_meteo = pd.json_normalize(vc_meteo_data, record_path=[\"days\", \"hours\"], meta=[\"days\"])\n",
    "\n",
    "# # Afficher la premi√®re ligne des donn√©es\n",
    "# df_vc_meteo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion du timestamp en datetime\n",
    "df_vc_meteo[\"Date\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%Y-%m-%d\")\n",
    "df_vc_meteo[\"Hour\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir les dates de filtrage pour les 30 derniers jours\n",
    "today = datetime.now()\n",
    "thirty_days_ago = today - timedelta(days=30)\n",
    "\n",
    "# Convertir les dates en format YYYY-MM-DD\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "thirty_days_ago_str = thirty_days_ago.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les donn√©es des 30 derniers jours de df_vc_meteo\n",
    "df_test_last_month = df_vc_meteo[['Date', 'Hour', 'windspeed']]\n",
    "df_test_last_month = df_test_last_month[(df_test_last_month['Date'] >= thirty_days_ago_str) & \n",
    "                                        (df_test_last_month['Date'] <= today_str)]\n",
    "\n",
    "# Ajouter les colonnes Date et Hour √† df_42058\n",
    "df_42058.loc[:, 'Date'] = df_42058['Datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "df_42058.loc[:, 'Hour'] = df_42058['Datetime'].dt.strftime(\"%H\")\n",
    "\n",
    "# Filtrer les donn√©es des 30 derniers jours dans df_42058\n",
    "df_42058_last_month = df_42058[(df_42058['Date'] >= thirty_days_ago_str) & \n",
    "                                (df_42058['Date'] <= today_str)]\n",
    "\n",
    "# Fusionner les deux DataFrames sur Date et Hour\n",
    "df_test_merged = df_test_last_month.merge(df_42058_last_month[['Date', 'Hour', 'Wind Speed (km/h)', 'wind_speed_10m']], \n",
    "                                     on=['Date', 'Hour'], \n",
    "                                     how='inner')\n",
    "\n",
    "df_test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def handle_null_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     row_count = df.shape[0]\n",
    "    \n",
    "#     # Initialisation des listes pour suivre les colonnes supprim√©es\n",
    "#     removed_columns = []\n",
    "#     non_numeric_columns_to_drop = []\n",
    "    \n",
    "#     # Utiliser lambda et apply() pour calculer le nombre de valeurs nulles dans chaque colonne\n",
    "#     null_counts = df.apply(lambda col: int(col.isnull().sum()))  # Calculer le nombre de NaN par colonne\n",
    "    \n",
    "#     # Condition : 1. Colonnes avec toutes les valeurs nulles ou 2. Plus de 50% de valeurs nulles et colonne non num√©rique\n",
    "#     columns_to_drop = null_counts[\n",
    "#         (null_counts == row_count) | \n",
    "#         ((null_counts > row_count * 0.5) & ~df.apply(lambda col: pd.api.types.is_numeric_dtype(col)))\n",
    "#     ].index\n",
    "    \n",
    "#     # Ajouter les noms des colonnes supprim√©es dans les listes appropri√©es\n",
    "#     for col in columns_to_drop:\n",
    "#         if null_counts[col] == row_count:\n",
    "#             removed_columns.append(col)  # Colonnes enti√®rement vides\n",
    "#         elif null_counts[col] > row_count * 0.5 and not pd.api.types.is_numeric_dtype(df[col]):\n",
    "#             non_numeric_columns_to_drop.append(col)  # Colonnes > 50% nulles et non num√©riques\n",
    "    \n",
    "#     # Supprimer les colonnes identifi√©es\n",
    "#     df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "#     # Afficher les r√©sultats\n",
    "#     print(\"Colonnes supprim√©es pour avoir toutes les valeurs nulles:\")\n",
    "#     print(removed_columns)\n",
    "    \n",
    "#     print(\"\\nColonnes supprim√©es pour avoir plus de 50% de valeurs nulles et √™tre non num√©riques:\")\n",
    "#     print(non_numeric_columns_to_drop)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# # df_final = pd.read_csv('ton_fichier.csv') # Assure-toi que df_final est bien un DataFrame valide avant d'appeler la fonction\n",
    "# df_final = handle_null_values(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = df_final.round(2)\n",
    "# print(df_final.columns)\n",
    "# df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def explore_dict_keys(d, parent_key='', sep='_'):\n",
    "#     \"\"\"\n",
    "#     Explore un dictionnaire r√©cursivement pour obtenir toutes les cl√©s, y compris les sous-cl√©s,\n",
    "#     mais ne retourne pas les valeurs finales.\n",
    "\n",
    "#     :param d: Le dictionnaire √† explorer\n",
    "#     :param parent_key: La cl√© parent qui est utilis√©e pour concat√©ner les sous-cl√©s\n",
    "#     :param sep: Le s√©parateur utilis√© pour concat√©ner les cl√©s (par d√©faut '_')\n",
    "#     :return: Une liste des cl√©s (et sous-cl√©s)\n",
    "#     \"\"\"\n",
    "#     keys = []\n",
    "#     for k, v in d.items():\n",
    "#         new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "#         if isinstance(v, dict):  # Si la valeur est un dictionnaire, on explore r√©cursivement\n",
    "#             keys.append(new_key)  # Ajouter la cl√©, mais ne pas inclure la valeur\n",
    "#             keys.extend(explore_dict_keys(v, new_key, sep=sep))  # Continuer l'exploration\n",
    "#         else:\n",
    "#             keys.append(new_key)  # Ajouter la cl√© finale\n",
    "#     return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_key_path(d, target_key, path=[]):\n",
    "#     \"\"\"\n",
    "#     Recherche r√©cursive d'une cl√© dans un dictionnaire et retourne son chemin.\n",
    "#     :param d: dictionnaire\n",
    "#     :param target_key: cl√© recherch√©e\n",
    "#     :param path: liste pour stocker le chemin jusqu'√† la cl√©\n",
    "#     :return: chemin sous forme de liste\n",
    "#     \"\"\"\n",
    "#     if isinstance(d, dict):  # Si le dictionnaire est encore imbriqu√©\n",
    "#         for key, value in d.items():\n",
    "#             new_path = path + [key]\n",
    "#             if key == target_key:\n",
    "#                 return new_path\n",
    "#             elif isinstance(value, dict):\n",
    "#                 result = find_key_path(value, target_key, new_path)\n",
    "#                 if result:  # Si la cl√© est trouv√©e, retourner le chemin\n",
    "#                     return result\n",
    "#     return None  # Retourne None si la cl√© n'a pas √©t√© trouv√©e\n",
    "\n",
    "\n",
    "\n",
    "# # Recherche du chemin pour la cl√© 'marine_data'\n",
    "# path = find_key_path(table_dict, \"Marine Dataframe\")\n",
    "# print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto_convert Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, (buoy_id, tables) in enumerate(table_dict.items()):  # Utilisation de .items() pour obtenir (cl√©, valeur)\n",
    "#     if isinstance(tables, dict):\n",
    "#         if idx == 1:  # V√©rifier si l'index est √©gal √† 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Rows of all Dataframes in total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
